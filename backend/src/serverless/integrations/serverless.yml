service: integrations
frameworkVersion: '3'
useDotenv: true

custom:
  webpack:
    keepOutputDirectory: true
    includeModules:
      forceInclude:
        - vm2
        - pg

  currentStage: ${opt:stage, self:provider.stage} # 'staging' is default unless overriden by --stage flag

  datadog:
    apiKeySecretArn: ${env:DATADOG_API_KEY_SECRET_ARN}
    enableXrayTracing: false
    enableDDTracing: true
    enableDDLogs: true
    site: datadoghq.eu
    captureLambdaPayload: true
    tags: 'context:integrations'
    enabled: ${strToBool(${env:DATADOG_ENABLED})}

  localstack:
    host: ${env:LOCALSTACK_HOSTNAME}
    edgePort: 4566
    stages:
      # list of stages for which the plugin should be enabled
      - local
    # host: ${env:LOCALSTACK_HOSTNAME}  # optional - LocalStack host to connect to
    # autostart: true  # optional - Start LocalStack in Docker on Serverless deploy
    lambda:
      # Enable this flag to improve performance
      mountCode: ${env:LOCALSTACK_LAMBDA_MOUNT_CODE, false}
    docker:
      # Enable this flag to run "docker ..." commands as sudo
      sudo: False
    debug: True

provider:
  name: aws
  runtime: nodejs14.x
  stage: staging
  memorySize: 5000 # optional, in MB, default is 1024
  timeout: 900 # optional, in seconds, default is 6
  iamRoleStatements:
    - Effect: 'Allow'
      Action:
        - 'states:StartExecution'
        - sqs:SendMessage
        - secretsmanager:GetSecretValue
      Resource:
        - '*'
    - Effect: 'Allow'
      Action:
        - s3:HeadObject
        - s3:GetObject
        - s3:PutObject
      Resource: 'arn:aws:s3:::${env:INTEGRATIONS_ASSETS_BUCKET}-${self:custom.currentStage}/*'
  region: ${env:AWS_REGION}

constructs:
  jobs:
    type: queue
    alarm: joan@crowd.dev
    max-retries: 2
    fifo: true
    batchSize: 1 # Lambda will receive 1 message at a time
    worker:
      timeout: 900
      handler: ./handler.consumer
      environment:
        NODE_ENV: ${env:NODE_ENV}
        EDITION: ${env:EDITION}
        SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
        INTEGRATIONS_STATEMACHINE_ARN: ${env:INTEGRATIONS_STATEMACHINE_ARN}
        LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
        LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}

functions:
  twitterCoordinator:
    handler: ./handler.handlerTwitterCoordinator
    events:
      - schedule: cron(0 */2 * * ? *)

    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  twitterReachCoordinator:
    handler: ./handler.handlerTwitterReachCoordinator
    events:
      - schedule: cron(0 7 * * ? *)
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  discordCoordinator:
    handler: ./handler.handlerDiscordCoordinator
    events:
      - schedule:
          rate: rate(20 minutes)
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  slackCoordinator:
    handler: ./handler.handlerSlackCoordinator
    events:
      - schedule:
          rate: rate(20 minutes)
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  devtoCoordinator:
    handler: ./handler.handlerDevtoCoordinator
    events:
      - schedule:
          rate: rate(2 hours)
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  githubWebhook:
    handler: ./apiHandler.handler
    events:
      - http:
          path: /webhooks/github
          method: POST
          cors: true
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      GITHUB_WEBHOOK_SECRET: ${env:GITHUB_WEBHOOK_SECRET, 'false'}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

  postWaitWorker:
    handler: ./handler.worker
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      INTEGRATIONS_SQS_URL: ${env:INTEGRATIONS_SQS_URL}
      NODE_MICROSERVICES_SQS_URL: ${env:NODE_MICROSERVICES_SQS_URL}
      SUPERFACE_SANDBOX_TIMEOUT: 1000
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_DIALECT: ${env:DATABASE_DIALECT}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DATABASE_HOST_WRITE: ${env:DATABASE_HOST_WRITE}
      DATABASE_LOGGING: ${env:DATABASE_LOGGING}
      INTEGRATIONS_ASSETS_BUCKET: ${env:INTEGRATIONS_ASSETS_BUCKET}
      TWITTER_LIMIT_RESET_FREQUENCY_DAYS: ${env:TWITTER_LIMIT_RESET_FREQUENCY_DAYS}
      AUTH_SOCIAL_TWITTER_CLIENT_ID: ${env:AUTH_SOCIAL_TWITTER_CLIENT_ID, 'false'}
      AUTH_SOCIAL_TWITTER_CLIENT_SECRET: ${env:AUTH_SOCIAL_TWITTER_CLIENT_SECRET, 'false'}
      DISCORD_TOKEN: ${env:DISCORD_TOKEN, 'false'}
      DISCORD_MAX_RETROSPECT_IN_SECONDS: ${env:DISCORD_MAX_RETROSPECT_IN_SECONDS}
      TWITTER_MAX_RETROSPECT_IN_SECONDS: ${env:TWITTER_MAX_RETROSPECT_IN_SECONDS}
      TWITTER_GLOBAL_LIMIT: ${env:TWITTER_GLOBAL_LIMIT}
      SUPERFACE_SDK_TOKEN: ${env:SUPERFACE_SDK_TOKEN}
      SEARCH_ENGINE_HOST: ${env:SEARCH_ENGINE_HOST}
      SEARCH_ENGINE_API_KEY: ${env:SEARCH_ENGINE_API_KEY}
      SERVICE: integrations

stepFunctions:
  stateMachines:
    integrationsStepFunction:
      name: IntegrationsStateMachine${self:custom.currentStage}
      definition:
        Comment: 'State machine that waits the required time for integrations rate limiting'
        StartAt: WaitState
        States:
          WaitState:
            Type: Wait
            SecondsPath: '$.sleep'
            Next: WorkerState
          WorkerState:
            Type: Task
            Resource:
              Fn::GetAtt: [postWaitWorker, Arn]
            End: true

resources:
  Outputs:
    IntegrationsWaitStateMachine:
      Description: The ARN of the example state machine
      Value:
        Ref: IntegrationsStateMachine${self:custom.currentStage}
  # Public Slack conversations need a bucket to store Slack attachments, since they are
  # not publically available
  Resources:
    IntegrationsAssetsBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${env:INTEGRATIONS_ASSETS_BUCKET}-${self:custom.currentStage}
        AccessControl: PublicRead
    # Define a public policy for the bucket
    IntegrationsAssetsBucketPolicy:
      Type: AWS::S3::BucketPolicy
      Properties:
        Bucket: !Ref IntegrationsAssetsBucket # this is the Bucket
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Action:
                - 's3:GetObject'
              Resource:
                # This is the ARN of the newly created Bucket
                - !Join ['/', [!GetAtt [IntegrationsAssetsBucket, Arn], '*']]
              Principal: '*'

plugins:
  - serverless-lift
  - serverless-step-functions
  - serverless-webpack
  - serverless-localstack
  - serverless-plugin-datadog
