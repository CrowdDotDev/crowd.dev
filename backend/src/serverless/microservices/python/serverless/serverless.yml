service: pythonMicroservices
frameworkVersion: '3'
useDotenv: true

provider:
  name: aws
  runtime: python3.8
  stage: staging
  memorySize: 3072 # optional, in MB, default is 1024
  timeout: 900 # optional, in seconds, default is 6
  iamRoleStatements:
    - Effect: 'Allow'
      Action:
        - 'states:StartExecution'
        - sqs:SendMessage
        - secretsmanager:GetSecretValue
      Resource:
        - '*'
  region: ${env:AWS_REGION}

custom:
  currentStage: ${opt:stage, self:provider.stage} # 'staging' is default unless overriden by --stage flag
  scripts:
    hooks:
      # The psycopg2-3.8 folder contains the psycopg2 package compiled for the lambda environment.
      # If it is installed using pip it only works when a linux machine has done the install.
      # We change the name to psycopg2 so lambda will use the folder as the psycopg2 package.
      # We need to rename because if it lives named as psycopg2 it overwrites the psycopg2 installation
      # that one might have in local, and thus functions cannot be invoked locally since the package
      # might not be compatible with our system.
      'package:initialize': cp -r psycopg2-3.8 psycopg2
      'deploy:finalize': rm -rf psycopg2

  localstack:
    host: ${env:LOCALSTACK_HOSTNAME}
    stages:
      # list of stages for which the plugin should be enabled
      - local
    ## Mounting is not supported with serverless-python-requirements plugin
    #lambda:
    #  # Enable this flag to improve performance
    #  mountCode: True
    docker:
      # Enable this flag to run "docker ..." commands as sudo
      sudo: False
    debug: True

constructs:
  jobs:
    type: queue
    alarm: joan@crowd.dev
    max-retries: 1
    fifo: true
    batchSize: 1 # Lambda will receive 1 message at a time
    worker:
      timeout: 900
      handler: handler_scheduled.worker
      environment:
        NODE_ENV: ${env:NODE_ENV}
        LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
        LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
        DATABASE_USERNAME: ${env:DATABASE_USERNAME}
        DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
        DATABASE_DATABASE: ${env:DATABASE_DATABASE}
        DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
        DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
        PYTHON_MICROSERVICES_SQS_URL: ${env:PYTHON_MICROSERVICES_SQS_URL}

functions:
  coordinator:
    handler: handler_scheduled.coordinator
    events:
      - schedule:
          rate: rate(2 hours)
          input:
            service: members_score
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      AWS_ACCESS_KEY_ID_CROWD: ${env:AWS_ACCESS_KEY_ID, false}
      AWS_SECRET_ACCESS_KEY_CROWD: ${env:AWS_SECRET_ACCESS_KEY, false}
      DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
      PYTHON_MICROSERVICES_SQS_URL: ${env:PYTHON_MICROSERVICES_SQS_URL}

  testSqs:
    handler: handler_scheduled.worker
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
      PYTHON_MICROSERVICES_SQS_URL: ${env:PYTHON_MICROSERVICES_SQS_URL}

  gitHubOnboardingCoordinator:
    handler: handler_github.onboarding_coordinator
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
      AWS_ACCESS_KEY_ID_CROWD: ${env:AWS_ACCESS_KEY_ID, false}
      AWS_SECRET_ACCESS_KEY_CROWD: ${env:AWS_SECRET_ACCESS_KEY, false}
      ONBOARDING_STATE_MACHINE_ARN: ${self:resources.Outputs.OnboardingStateMachine.Value}

  gitHubOnboardingWorker:
    handler: handler_github.onboarding_worker
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
      AWS_ACCESS_KEY_ID_CROWD: ${env:AWS_ACCESS_KEY_ID, false}
      AWS_SECRET_ACCESS_KEY_CROWD: ${env:AWS_SECRET_ACCESS_KEY, false}

  gitHubOnboardingStatus:
    handler: handler_github.onboarding_status
    environment:
      NODE_ENV: ${env:NODE_ENV}
      EDITION: ${env:EDITION}
      SEGMENT_WRITE_KEY: ${env:SEGMENT_WRITE_KEY}
      LOCALSTACK_HOSTNAME: ${env:LOCALSTACK_HOSTNAME}
      LOCALSTACK_PORT: ${env:LOCALSTACK_PORT}
      AWS_ACCOUNT_ID: ${env:AWS_ACCOUNT_ID}
      CROWD_AWS_REGION: ${env:AWS_REGION}
      DATABASE_USERNAME: ${env:DATABASE_USERNAME}
      DATABASE_PASSWORD: ${env:DATABASE_PASSWORD}
      DATABASE_DATABASE: ${env:DATABASE_DATABASE}
      DATABASE_HOST_READ: ${env:DATABASE_HOST_WRITE}
      DB_OPERATIONS_SQS_URL: ${env:DB_OPERATIONS_SQS_URL}
      AWS_ACCESS_KEY_ID_CROWD: ${env:AWS_ACCESS_KEY_ID, false}
      AWS_SECRET_ACCESS_KEY_CROWD: ${env:AWS_SECRET_ACCESS_KEY, false}

stepFunctions:
  stateMachines:
    #Â Onboarding state machine
    onboardingStateMachine:
      name: OnboardingStateMachine${self:custom.currentStage}
      definition:
        Comment: 'State machine that coordinates GitHub onboarding'
        StartAt: WaitState
        States:
          WaitState:
            Type: Wait
            SecondsPath: '$.wait'
            Next: MapState
          MapState:
            Type: Map
            Iterator:
              StartAt: WorkerState
              States:
                WorkerState:
                  Type: Task
                  Resource:
                    Fn::GetAtt: [gitHubOnboardingWorker, Arn]
                  End: true
            ItemsPath: '$.events'
            Next: StatusState
          StatusState:
            Type: Task
            Resource:
              Fn::GetAtt: [gitHubOnboardingStatus, Arn]
            End: true

resources:
  Outputs:
    OnboardingStateMachine:
      Description: The ARN of the onboarding state machine
      Value:
        Ref: OnboardingStateMachine${self:custom.currentStage}

package:
  include:
    - '../crowd-backend/**'
    - '../crowd-github/**'
    - '../crowd-members-score/**'
    - '../crowd-check-merge-members/**'
  patterns:
    - '!venv*/**'

plugins:
  - serverless-lift
  - serverless-step-functions
  - serverless-plugin-scripts
  - serverless-localstack
